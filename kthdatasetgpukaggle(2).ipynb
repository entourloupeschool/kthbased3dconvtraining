{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T11:10:23.989885Z","iopub.status.busy":"2023-05-29T11:10:23.989411Z","iopub.status.idle":"2023-05-29T11:10:23.996243Z","shell.execute_reply":"2023-05-29T11:10:23.994943Z","shell.execute_reply.started":"2023-05-29T11:10:23.989839Z"},"trusted":true},"outputs":[],"source":["# This database contains sequences of six classes of actions performed by\n","# 25 subjects in four different conditions d1-d4\n","\n","# d1 - Static homogenous background\n","# d2 - -\"-                          + Scale variations\n","# d3 - -\"-                          + Different clothes\n","# d4 - -\"-                          + Lighting variations\n","\n","# Training:   person11, 12, 13, 14, 15, 16, 17, 18\n","# Validation: person19, 20, 21, 23, 24, 25, 01, 04\n","# Test:       person22, 02, 03, 05, 06, 07, 08, 09, 10 "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T11:17:28.536567Z","iopub.status.busy":"2023-05-29T11:17:28.536081Z","iopub.status.idle":"2023-05-29T11:18:03.158577Z","shell.execute_reply":"2023-05-29T11:18:03.157241Z","shell.execute_reply.started":"2023-05-29T11:17:28.536530Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: av in /opt/conda/lib/python3.10/site-packages (10.0.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","Collecting moviepy\n","  Downloading moviepy-1.0.3.tar.gz (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n","  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.64.1)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.28.2)\n","Collecting proglog<=1.0.0 (from moviepy)\n","  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.23.5)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.28.1)\n","Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n","  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.5.7)\n","Building wheels for collected packages: moviepy\n","  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110744 sha256=f701e220a91144819b884f7b61263d479a5aab364803f0c208b5dbee1ab8f396\n","  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\n","Successfully built moviepy\n","Installing collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n","  Attempting uninstall: decorator\n","    Found existing installation: decorator 5.1.1\n","    Uninstalling decorator-5.1.1:\n","      Successfully uninstalled decorator-5.1.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyterlab-lsp 4.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.8 moviepy-1.0.3 proglog-0.1.10\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install av\n","%pip install moviepy"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:04:48.807008Z","iopub.status.busy":"2023-05-29T12:04:48.806630Z","iopub.status.idle":"2023-05-29T12:04:48.816984Z","shell.execute_reply":"2023-05-29T12:04:48.815784Z","shell.execute_reply.started":"2023-05-29T12:04:48.806978Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["This machine has 2 CPU cores.\n","cuda:0\n"]}],"source":["import os\n","import torch\n","from torch.utils.data import Dataset\n","import numpy as np\n","from PIL import Image\n","import av\n","import random as rdm\n","import torchvision.transforms.v2 as transforms\n","from tqdm import tqdm\n","\n","import os\n","import torch\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset\n","from torchvision.io import read_video\n","from torch.utils.data import DataLoader\n","import torchvision\n","import multiprocessing\n","import time\n","from torch.nn.utils.rnn import pad_sequence\n","\n","num_cores = multiprocessing.cpu_count()\n","\n","print(\"This machine has {} CPU cores.\".format(num_cores))\n","\n","def set_seed(seed=42):\n","    rdm.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    return seed\n","\n","set_seed()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:04:50.032018Z","iopub.status.busy":"2023-05-29T12:04:50.031654Z","iopub.status.idle":"2023-05-29T12:04:51.411784Z","shell.execute_reply":"2023-05-29T12:04:51.410616Z","shell.execute_reply.started":"2023-05-29T12:04:50.031990Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-05-29 12:04:50--  https://github.com/rdfia/rdfia.github.io/raw/master/code/2-cd/utils.py\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/2-cd/utils.py [following]\n","--2023-05-29 12:04:51--  https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/2-cd/utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2627 (2.6K) [text/plain]\n","Saving to: ‘utils.py.1’\n","\n","utils.py.1          100%[===================>]   2.57K  --.-KB/s    in 0s      \n","\n","2023-05-29 12:04:51 (40.2 MB/s) - ‘utils.py.1’ saved [2627/2627]\n","\n"]}],"source":["! wget https://github.com/rdfia/rdfia.github.io/raw/master/code/2-cd/utils.py\n","from utils import *"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:05:15.124104Z","iopub.status.busy":"2023-05-29T12:05:15.123732Z","iopub.status.idle":"2023-05-29T12:05:15.612580Z","shell.execute_reply":"2023-05-29T12:05:15.611371Z","shell.execute_reply.started":"2023-05-29T12:05:15.124069Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["FPS:  25.0\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The shortest sequence is in video person10_handclapping_d1 from frame 261 to 284 with a length of 24 frames.\n"]}],"source":["# histogram with the distribution of the number of frames per video\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from moviepy.editor import VideoFileClip\n","\n","clip = VideoFileClip(\"/kaggle/input/kth-raw/KTH/boxing/person01_boxing_d1_uncomp.avi\")\n","print(\"FPS: \", clip.fps)\n","\n","shortest_sequence = None\n","shortest_length = float('inf')\n","txt_path = '/kaggle/input/kth-raw/KTH/sequences.txt'\n","with open(txt_path, 'r') as f:\n","    lines = f.readlines()\n","    lengths = []\n","    for line in lines:\n","        video_id, *frame_sequences = line.strip().split(',')\n","        for frame_sequence in frame_sequences:\n","            start, end = map(int, frame_sequence.split('-'))\n","            length = end - start + 1\n","            lengths.append(length)\n","            if length < shortest_length:\n","                shortest_sequence = (video_id, start, end)\n","                shortest_length = length\n","            \n","plt.hist(lengths, bins=100)\n","plt.xlabel('Number of frames')\n","plt.ylabel('Number of sequence')\n","plt.title('Distribution of the number of frames per sequence')\n","plt.show()\n","\n","print(f\"The shortest sequence is in video {shortest_sequence[0]} from frame {shortest_sequence[1]} to {shortest_sequence[2]} with a length of {shortest_length} frames.\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:05:15.615117Z","iopub.status.busy":"2023-05-29T12:05:15.614749Z","iopub.status.idle":"2023-05-29T12:05:15.622936Z","shell.execute_reply":"2023-05-29T12:05:15.620109Z","shell.execute_reply.started":"2023-05-29T12:05:15.615082Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2086 videos have more than 50 frames.\n","\n"," That is 87.24% of the videos.\n"]}],"source":["# how many segments have more than N frames?\n","num_frames = 50\n","sum_frames = sum([length > num_frames for length in lengths])\n","print(f\"{sum_frames} videos have more than {num_frames} frames.\\n\\n That is {sum_frames/len(lengths)*100:.2f}% of the videos.\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:07:07.295679Z","iopub.status.busy":"2023-05-29T12:07:07.295296Z","iopub.status.idle":"2023-05-29T12:07:07.315132Z","shell.execute_reply":"2023-05-29T12:07:07.314152Z","shell.execute_reply.started":"2023-05-29T12:07:07.295645Z"},"trusted":true},"outputs":[],"source":["# training are persons :11, 12, 13, 14, 15, 16, 17, 18\n","# validation are persons : 19, 20, 21, 23, 24, 25, 01, 04\n","# test are persons : 22, 02, 03, 05, 06, 07, 08, 09, 10\n","# https://pytorch.org/vision/main/auto_examples/plot_optical_flow.html#sphx-glr-auto-examples-plot-optical-flow-py\n","def frame_to_sec(frame):\n","    frames_per_second = 25\n","    return frame/frames_per_second\n","\n","class KTHDataset(Dataset):\n","    def __init__(self, root, txt_path, transforms=None, subset='train', num_frames=16):\n","        self.root = root\n","        self.transforms = transforms\n","        self.subset = subset\n","        self.data = []\n","        self.num_frames = num_frames\n","        self.label_to_int = {\"boxing\": 0, \"handclapping\": 1, \"handwaving\": 2,\n","                             \"jogging\": 3, \"running\": 4, \"walking\": 5}\n","        self.int_to_label = {v: k for k, v in self.label_to_int.items()}\n","\n","        with open(txt_path, 'r') as f:\n","            lines = f.readlines()\n","            for line in lines:\n","                video_id, *frame_sequences = line.strip().split(',')\n","                person_id, action, _ = video_id.split('_')\n","\n","                person_number = int(person_id.replace(\"person\", \"\"))\n","                \n","                if self._is_in_subset(person_number):\n","                    for frame_sequence in frame_sequences:\n","                        start, end = frame_sequence.split('-')\n","                        if int(end) - int(start) + 1 >= self.num_frames:\n","                            self.data.append((video_id, frame_to_sec(int(start)), frame_to_sec(int(start) + self.num_frames - 1), self.label_to_int[action])) # truncates the sequence to num_frames\n","\n","    def get_action(self, label):\n","        return self.int_to_label[label]\n","    \n","    def _is_in_subset(self, person_number):\n","        # check if the person number is in the subset\n","        if self.subset == 'train':\n","            return person_number in [11, 12, 13, 14, 15, 16, 17, 18, 22, 2, 3, 5, 6]\n","        elif self.subset == 'validation':\n","            return person_number in [19, 20, 21, 23, 24, 25, 1, 4, 7, 8, 9, 10]\n","        elif self.subset == 'test':\n","            return person_number in [] # i don't need to test so dispatched all persons on train and valid\n","        else:\n","            return False\n","        \n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        video_id, start_frame, end_frame, action = self.data[idx]\n","        video_path = os.path.join(self.root+'/'+self.get_action(action)+'/', video_id+'_uncomp' + '.avi')\n","        print(start_frame, end_frame)\n","        video, audio, info = read_video(video_path, start_frame, end_frame, output_format=\"TCHW\", pts_unit='sec')\n","\n","        if self.transforms:\n","            video = self.transforms(video)\n","        \n","        # permute from TCHW to CTHW\n","        video = torch.permute(video, (1, 0, 2, 3)) # (C, T, H, W)\n","        \n","        # make sure that all videos have the same number of frames\n","        if video.shape[1] < self.num_frames:\n","            # pad the video with the last frame\n","            video = F.pad(video, (0, 0, 0, 0, 0, self.num_frames - video.shape[1]), mode='replicate')\n","        elif video.shape[1] > self.num_frames:\n","            # truncate the video\n","            video = video[:, :self.num_frames, :, :]\n","            \n","        return video, action"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:07:07.612914Z","iopub.status.busy":"2023-05-29T12:07:07.612541Z","iopub.status.idle":"2023-05-29T12:07:07.622470Z","shell.execute_reply":"2023-05-29T12:07:07.621362Z","shell.execute_reply.started":"2023-05-29T12:07:07.612884Z"},"trusted":true},"outputs":[],"source":["def get_loaders(data_path, sequences_path, resized, batch_size=4, cuda=True, num_workers=2, num_frames=22):\n","    transform_outer = transforms.Compose([\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n","        transforms.RandomHorizontalFlip(),\n","    ])\n","\n","    transform_inner = transforms.Compose([\n","        #transforms.Resize(resized, antialias=True),\n","        transforms.ToImageTensor(),\n","        transforms.ConvertImageDtype(torch.float32),\n","        transforms.Normalize([0.5], [0.5])\n","    ])\n","\n","    transform_train = transforms.Compose([\n","        transform_outer,\n","        transform_inner\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transform_inner\n","    ])\n","    \n","    train_dataset = KTHDataset(data_path, sequences_path, transforms=transform_train, subset='train', num_frames=num_frames)\n","    val_dataset = KTHDataset(data_path, sequences_path, transforms=transform_test, subset='validation', num_frames=num_frames)\n","    test_dataset = KTHDataset(data_path, sequences_path, transforms=transform_test, subset='test', num_frames=num_frames)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=cuda)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=cuda)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=cuda)\n","\n","    return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:07:08.062945Z","iopub.status.busy":"2023-05-29T12:07:08.062270Z","iopub.status.idle":"2023-05-29T12:07:13.140811Z","shell.execute_reply":"2023-05-29T12:07:13.139221Z","shell.execute_reply.started":"2023-05-29T12:07:08.062911Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["10.427.6  12.3629.56\n","\n","7.08.72  8.9610.68\n","\n","3.64 5.60.04\n"," 2.0\n","5.48 7.44\n","5.12 7.08\n","11.0 12.96\n","8.44 10.4\n","15.8 17.76\n","12.36 14.32\n","8.24 10.2\n","10.6 12.56\n","15.32 17.28\n","0.04 2.0\n","9.88 11.84\n","5.36 7.32\n"]},{"name":"stderr","output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b89adac9ea0>\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","Exception ignored in:   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b89adac9ea0>    \n","if w.is_alive():Traceback (most recent call last):\n","\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()\n","AssertionError: \n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","can only test a child process    if w.is_alive():\n","\n","  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b89adac9ea0>assert self._parent_pid == os.getpid(), 'can only test a child process'\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","\n","    AssertionError: self._shutdown_workers()can only test a child process\n","\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","Exception ignored in:     assert self._parent_pid == os.getpid(), 'can only test a child process'\n","<function _MultiProcessingDataLoaderIter.__del__ at 0x7b89adac9ea0>AssertionError: can only test a child process\n","\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"name":"stdout","output_type":"stream","text":["11.88 13.84\n","11.04 13.0\n","4.12 6.0810.08\n"," 12.04\n"]},{"ename":"RuntimeError","evalue":"Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 50, 120, 160] at entry 0 and [3, 51, 120, 160] at entry 1\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m sequences_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/kth-raw/KTH/sequences.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m train_set, valid_set, _ \u001b[38;5;241m=\u001b[39m get_loaders(data_path, sequences_path, (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m), \u001b[38;5;241m10\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (videos, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_set):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape of batch :\u001b[39m\u001b[38;5;124m'\u001b[39m, videos\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# should get [batch_size, 3, seq_len, resized[0], resized[1]]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# should get [batch_size], the labels of the videos in the batch\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 50, 120, 160] at entry 0 and [3, 51, 120, 160] at entry 1\n"]},{"name":"stdout","output_type":"stream","text":["6.0 7.96\n","4.32 6.28\n","17.0 18.96\n","13.52 15.48\n","0.04 2.0\n","8.2 10.16\n","5.4 7.36\n","0.04 2.0\n","9.08 11.04\n","25.6 27.56\n","14.8 16.76\n","0.04 2.0\n","9.44 11.4\n","4.6 6.56\n","26.0 27.966.8 \n","8.76\n","9.28 11.24\n","9.2 11.16\n","3.32 5.28\n","16.88 18.84\n","4.44 6.4\n","5.12 7.08\n","9.8 11.76\n","14.12 16.08\n","0.04 2.0\n","9.4 11.36\n","7.4 9.36\n","12.2 14.16\n"]}],"source":["# Test the dataloader\n","data_path = '/kaggle/input/kth-raw/KTH'\n","sequences_path = '/kaggle/input/kth-raw/KTH/sequences.txt'\n","\n","train_set, valid_set, _ = get_loaders(data_path, sequences_path, (64, 64), 10, False, 2, 50)\n","for i, (videos, labels) in enumerate(train_set):\n","    print('shape of batch :', videos.shape) # should get [batch_size, 3, seq_len, resized[0], resized[1]]\n","    print(labels.shape) # should get [batch_size], the labels of the videos in the batch\n","    if i == 5:\n","        break\n","        \n","for i, (videos, labels) in enumerate(valid_set):\n","    print('shape of batch :', videos.shape) # should get [batch_size, 3, seq_len, resized[0], resized[1]]\n","    print(labels.shape) # should get [batch_size], the labels of the videos in the batch\n","    if i == 5:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-29T12:05:25.128139Z","iopub.status.idle":"2023-05-29T12:05:25.131581Z","shell.execute_reply":"2023-05-29T12:05:25.131328Z","shell.execute_reply.started":"2023-05-29T12:05:25.131296Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","    \n","class Simple3DCNN(nn.Module):\n","    def __init__(self, num_classes=6, in_channels=3, dropout_prob=0.5):\n","        super(Simple3DCNN, self).__init__()\n","        self.conv1 = nn.Conv3d(in_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n","        self.bn1 = nn.BatchNorm3d(32)\n","        self.relu = nn.ReLU(inplace=True) # ReLU activation\n","        self.maxpool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n","        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n","        self.bn2 = nn.BatchNorm3d(64)\n","        self.maxpool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","        self.conv3 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n","        self.bn3 = nn.BatchNorm3d(128)\n","        self.maxpool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n","        self.dropout = nn.Dropout(dropout_prob)\n","        self.fc = nn.Linear(38400, num_classes)\n","        \n","    def forward(self, x):\n","        # print(x.shape)\n","        x = self.conv1(x)\n","        # print(x.shape)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool1(x)\n","        # print(x.shape)\n","        x = self.conv2(x)\n","        # print(x.shape)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.maxpool2(x)\n","        # print(x.shape)\n","        x = self.conv3(x)\n","        # print(x.shape)\n","        x = self.bn3(x)\n","        x = self.relu(x)\n","        x = self.maxpool3(x)\n","        # print(x.shape)\n","        #x = self.dropout(x)\n","        x = x.view(x.shape[0], -1)\n","        # print(x.shape)\n","        x = self.fc(x)\n","        # print(x.shape)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-29T12:05:25.142174Z","iopub.status.idle":"2023-05-29T12:05:25.142827Z","shell.execute_reply":"2023-05-29T12:05:25.142581Z","shell.execute_reply.started":"2023-05-29T12:05:25.142556Z"},"trusted":true},"outputs":[],"source":["class Metric: \n","    def __init__(self):\n","        self.loss_train = []\n","        self.loss_test = []\n","        self.acc_train = []\n","        self.acc_test = []\n","    \n","def epoch(data, model, criterion, optimizer=None, cuda=False):\n","    \"\"\"\n","    Make a pass (called epoch in English) on the data `data` with the\n","     model `model`. Evaluates `criterion` as loss.\n","     If `optimizer` is given, perform a training epoch using\n","     the given optimizer, otherwise, perform an evaluation epoch (no backward)\n","     of the model.\n","    \"\"\"\n","\n","    # indicates whether the model is in eval or train mode (some layers behave differently in train and eval)\n","    model.eval() if optimizer is None else model.train()\n","\n","    # objects to store metric averages\n","    avg_loss = AverageMeter()\n","    avg_top1_acc = AverageMeter()\n","    avg_top5_acc = AverageMeter()\n","    avg_batch_time = AverageMeter()\n","    global loss_plot\n","\n","    # we iterate on the batches\n","    tic = time.time()\n","    for i, (input, target) in enumerate(data):\n","        \n","        if cuda: # only with GPU, and not with CPU\n","            input = input.cuda()\n","            target = target.cuda()\n","\n","        # forward\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # backward if we are training\n","        if optimizer:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # compute metrics\n","        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n","        batch_time = time.time() - tic\n","        tic = time.time()\n","\n","        # update\n","        avg_loss.update(loss.item())\n","        avg_top1_acc.update(prec1.item())\n","        avg_top5_acc.update(prec5.item())\n","        avg_batch_time.update(batch_time)\n","        if optimizer:\n","            loss_plot.update(avg_loss.val)\n","        # print info\n","        #if i % PRINT_INTERVAL == 0:\n","        #    print('[{0:s} Batch {1:03d}/{2:03d}]\\t'\n","        #          'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t'\n","        #          'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","        #          'Prec@1 {top1.val:5.1f} ({top1.avg:5.1f})\\t'\n","        #          'Prec@5 {top5.val:5.1f} ({top5.avg:5.1f})'.format(\n","        #           \"EVAL\" if optimizer is None else \"TRAIN\", i, len(data), batch_time=avg_batch_time, loss=avg_loss,\n","        #           top1=avg_top1_acc, top5=avg_top5_acc))\n","            #if optimizer:\n","                #loss_plot.plot()\n","\n","    # Print summary\n","    #print('\\n===============> Total time {batch_time:d}s\\t'\n","    #      'Avg loss {loss.avg:.4f}\\t'\n","    #      'Avg Prec@1 {top1.avg:5.2f} %\\t'\n","    #      'Avg Prec@5 {top5.avg:5.2f} %\\n'.format(\n","    #       batch_time=int(avg_batch_time.sum), loss=avg_loss,\n","    #       top1=avg_top1_acc, top5=avg_top5_acc))\n","\n","    return avg_top1_acc, avg_top5_acc, avg_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-29T12:05:25.145323Z","iopub.status.idle":"2023-05-29T12:05:25.145801Z","shell.execute_reply":"2023-05-29T12:05:25.145566Z","shell.execute_reply.started":"2023-05-29T12:05:25.145544Z"},"trusted":true},"outputs":[],"source":["from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","\n","def main(data_path, sequences_path, resized, num_frames, batch_size=128, lr=0.1, epochs=5, cuda=False, num_workers=2, dropout_prob=0.1):\n","\n","    # define model, loss, optim\n","    model = Simple3DCNN(dropout_prob=dropout_prob)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr)\n","\n","    scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","\n","    if cuda: # only with GPU, and not with CPU\n","        cudnn.benchmark = True\n","        model = model.cuda()\n","        criterion = criterion.cuda()\n","\n","    # Get the data\n","    train, test, _ = get_loaders(data_path, sequences_path, resized, batch_size, cuda, num_workers, num_frames)\n","\n","    # init plots\n","    listm = []\n","    #plot = AccLossPlot()\n","    global loss_plot\n","    loss_plot = TrainLossPlot()\n","    #accs_train= []\n","    #accs_test= []\n","\n","    # We iterate on the epochs\n","    for i in tqdm(range(epochs)):\n","        m = Metric()\n","\n","        # Train phase\n","        top1_acc, avg_top5_acc, loss = epoch(train, model, criterion, optimizer, cuda)\n","        # Update learning rate\n","        scheduler.step()\n","\n","        # Test phase\n","        top1_acc_test, top5_acc_test, loss_test = epoch(test, model, criterion, cuda=cuda)\n","        # plot\n","        #plot.update(loss.avg, loss_test.avg, top1_acc.avg, top1_acc_test.avg)\n","        m.acc_train = top1_acc.avg\n","        m.acc_test = top1_acc_test.avg\n","        m.loss_train = loss.avg\n","        m.loss_test = loss_test.avg\n","        listm.append(m)\n","        print( f\"********** EPOCH {i+1} acc train={m.acc_train:.2f}%, acc test={m.acc_test:.2f}%, loss train={m.loss_train:.3f}, loss test={m.loss_test:.3f} **********\")\n","        #accs_train.append(top1_acc_ = test)\n","        #accs_test.append(top1_acc_test)\n","\n","    return listm"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:05:37.445807Z","iopub.status.busy":"2023-05-29T12:05:37.445429Z","iopub.status.idle":"2023-05-29T12:05:41.390681Z","shell.execute_reply":"2023-05-29T12:05:41.387350Z","shell.execute_reply.started":"2023-05-29T12:05:37.445773Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/40 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b89adac9ea0>\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b89adac9ea0>\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n","    self._shutdown_workers()\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","  0%|          | 0/40 [00:03<?, ?it/s]\n"]},{"ename":"RuntimeError","evalue":"Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 4, 120, 160] at entry 0 and [3, 5, 120, 160] at entry 14\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     13\u001b[0m num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequences_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 34\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_path, sequences_path, resized, num_frames, batch_size, lr, epochs, cuda, num_workers, dropout_prob)\u001b[0m\n\u001b[1;32m     31\u001b[0m m \u001b[38;5;241m=\u001b[39m Metric()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Train phase\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m top1_acc, avg_top5_acc, loss \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Update learning rate\u001b[39;00m\n\u001b[1;32m     36\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n","Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mepoch\u001b[0;34m(data, model, criterion, optimizer, cuda)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# we iterate on the batches\u001b[39;00m\n\u001b[1;32m     28\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cuda: \u001b[38;5;66;03m# only with GPU, and not with CPU\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcuda()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 4, 120, 160] at entry 0 and [3, 5, 120, 160] at entry 14\n"]},{"data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["data_path = '/kaggle/input/kth-raw/KTH'\n","sequences_path = '/kaggle/input/kth-raw/KTH/sequences.txt'\n","\n","resized = (64, 64)\n","batch_size = 4\n","\n","lr = 0.0001\n","epochs = 40\n","cuda = torch.cuda.is_available()\n","num_workers = 2\n","dropout_prob = 0.1\n","\n","num_frames = 50\n","\n","main(data_path, sequences_path, resized, batch_size, num_frames, lr, epochs, cuda, num_workers, dropout_prob)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
